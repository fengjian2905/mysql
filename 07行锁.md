# 行锁

> MySQL 的行锁是在引擎层，由各个引擎自己实现的

## 两阶段锁

> InnDB事务中，行锁是在需要的时候加上的，但并不是不需要了就立刻释放，而是要等到
> 事务结束才释放。这就是两阶段锁协议！

1. 事务A
   
    ```sql
        begin;
        update t set k=k+1 where id=1;
        update t set k=k+1 where id=2;
    ```

2. 事务B
   
    ```sql
        begin;
        update t set k=k+2 where id=1;
    ```

3. 事务A
   
   ```sql
    commit;
   ```
事务 B 的update语句会被阻塞，直到事务 A 执行commit后，事务 B 才能继续执行

## 两阶段锁带给我们的现时启示

> 在一个事务中，把最可能造成锁冲突、最可能影响并发度的锁尽量往后放

## 死锁和死锁检测

**问题：**
线上 MySQL 挂了，服务器 CPU 消耗接近 100%，但整个数据库每秒就执行不到100
个事务？？

1. 死锁定义

> 当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源，这几个线程都进入无限等待的状态

2. 解决策略
   
   * 进入等待，直到超时， `innodb_lock_wait_timeout`设置锁等待超时时间，默认 `50s`
   * 死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行，`innodb_deadlock_detect`设置为on，开启死锁检测
  
3. 两种策略分析
   
   * innodb_lock_wati_timeout: 设置过大，对于在线服务等待时间无法忍受；设置过小，容易误伤
   * 死锁检测是通常被采用的策略

4. 死锁检测带来的 CPU 资源消耗过多！

    开启死锁检测后，每个新来的被堵住的线程都会判断会不会由于自己的加入导致了死锁; 
    假设有 1000 个并发线程要同时更新一行，那么死锁检测操作就是 100 万这个量级; 
    虽然最终检测没有发生死锁，但是这期间要消耗大量的CPU资源;


5. 那开启不是，不开启也不是，到底怎么样？
   
   * 治标不治本的方法：临时把死锁检测关闭，这可能导致大量超时
   * 控制并发度：在数据库服务端控制，如果在客户端做，一个应用600个客户端，每个只有5个并发 CPU 也是无法忍受的！
   * 在服务器端控制思路就是：对于相同行的更新，进入引擎前排队
   * 设计上优化：比如把要更新的一行记录拆成多行存储，每次更新随机取出一行，如此便可减少锁冲突

6. 问题：
   
    要删除表里面的 10000 行数据，有如下方式： 
    * 第一种，直接执行 delete from T limit 10000
    * 第二种，在一个连接中循环执行 20 次 delete from T limit 500
    * 第三种，在 20 个连接中同时执行 delete from T limit 500
    你会选择哪种？

    第一种： 造成长事务，锁时间过长
    第二种：较为理想
    第三种：造成锁冲突过多





